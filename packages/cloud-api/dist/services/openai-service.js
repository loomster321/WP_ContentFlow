"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.OpenAIService = void 0;
const openai_1 = __importDefault(require("openai"));
const logger_1 = require("../utils/logger");
class OpenAIService {
    client;
    constructor() {
        const apiKey = process.env.OPENAI_API_KEY;
        if (!apiKey) {
            throw new Error('OPENAI_API_KEY environment variable is required');
        }
        this.client = new openai_1.default({
            apiKey: apiKey
        });
    }
    async generateContent(request) {
        const startTime = Date.now();
        try {
            logger_1.aiLogger.info('Sending request to OpenAI', {
                model: request.model,
                messageCount: request.messages.length,
                temperature: request.temperature,
                maxTokens: request.maxTokens
            });
            const completion = await this.client.chat.completions.create({
                model: request.model,
                messages: request.messages,
                temperature: request.temperature,
                max_tokens: request.maxTokens,
                stream: false
            });
            const content = completion.choices[0]?.message?.content || '';
            const usage = completion.usage;
            if (!content) {
                throw new Error('No content generated by OpenAI');
            }
            const processingTime = (Date.now() - startTime) / 1000;
            // Calculate confidence score based on response quality indicators
            const confidenceScore = this.calculateConfidenceScore(content, completion);
            const response = {
                content,
                confidenceScore,
                tokenUsage: {
                    promptTokens: usage?.prompt_tokens || 0,
                    completionTokens: usage?.completion_tokens || 0,
                    totalTokens: usage?.total_tokens || 0
                },
                processingTime,
                agentUsed: 'openai',
                metadata: {
                    model: request.model,
                    temperature: request.temperature,
                    finishReason: completion.choices[0]?.finish_reason,
                    openaiId: completion.id
                }
            };
            logger_1.aiLogger.info('OpenAI request completed', {
                contentLength: content.length,
                tokenUsage: response.tokenUsage,
                processingTime,
                confidenceScore
            });
            return response;
        }
        catch (error) {
            const processingTime = (Date.now() - startTime) / 1000;
            logger_1.aiLogger.error('OpenAI request failed', {
                error: error instanceof Error ? error.message : String(error),
                processingTime,
                model: request.model
            });
            throw error;
        }
    }
    /**
     * Calculate confidence score based on response characteristics
     */
    calculateConfidenceScore(content, completion) {
        let score = 0.5; // Base score
        // Content length indicator (not too short, not cut off)
        const wordCount = content.split(' ').length;
        if (wordCount >= 10 && wordCount <= 1000) {
            score += 0.2;
        }
        // Completion finished naturally
        if (completion.choices[0]?.finish_reason === 'stop') {
            score += 0.2;
        }
        // Content quality indicators
        const hasStructure = content.includes('.') || content.includes('!') || content.includes('?');
        if (hasStructure) {
            score += 0.1;
        }
        // Not cut off abruptly
        const endsWell = content.trim().match(/[.!?]$/);
        if (endsWell) {
            score += 0.1;
        }
        return Math.min(score, 1.0);
    }
    /**
     * Test API connection and configuration
     */
    async testConnection() {
        try {
            await this.client.chat.completions.create({
                model: 'gpt-3.5-turbo',
                messages: [{ role: 'user', content: 'Test connection' }],
                max_tokens: 5,
                temperature: 0.1
            });
            logger_1.aiLogger.info('OpenAI connection test successful');
            return true;
        }
        catch (error) {
            logger_1.aiLogger.error('OpenAI connection test failed', {
                error: error instanceof Error ? error.message : String(error)
            });
            return false;
        }
    }
    /**
     * Get available models
     */
    async getAvailableModels() {
        try {
            const models = await this.client.models.list();
            const chatModels = models.data
                .filter(model => model.id.includes('gpt'))
                .map(model => model.id)
                .sort();
            return chatModels;
        }
        catch (error) {
            logger_1.aiLogger.error('Failed to fetch OpenAI models', {
                error: error instanceof Error ? error.message : String(error)
            });
            return ['gpt-3.5-turbo', 'gpt-4', 'gpt-4-turbo-preview']; // Fallback
        }
    }
}
exports.OpenAIService = OpenAIService;
